# Trustworthy AI

可信人工智能（Trustworthy AI）并非一个静止的技术规范，而是一个不断演进的社会技术共识。它的出现标志着人工智能领域的一次深刻范式转移——从单纯追求性能和效率，转向全面关注其对人类和社会的深远影响。这一领域旨在确保人工智能系统的开发和部署是合法的、合乎道德的，并且在技术上是稳健的。具体来说，它包括以下几个方面：

- 公平性与包容性（Fairness & Inclusiveness）：要求AI系统公平对待所有个体和群体，避免产生或加剧有害的偏见和歧视性结果 。   

- 透明度与可解释性（Transparency & Explainability）：AI系统的决策过程必须对人类开放和可理解，以解决“黑箱”问题，使用户能够洞察其工作原理 。   

- 鲁棒性与可靠性（Robustness & Reliability）：系统必须能够安全、稳定地运行，在预期条件下提供一致的结果，并能抵御意外情况或恶意攻击 。   

- 隐私与安全（Privacy & Security）：AI系统必须保护用户数据的机密性和完整性，防止未经授权的访问和数据泄露，并遵守相关数据保护法规 。   

本次主要关注LLM的隐私安全，需要你从如下的论文选读**4篇**，并给出你对你选中的文章的一些思考，具体来说，讲清楚几个问题：他研究了/发现了一个什么有意思的问题，之后用什么样的方式解决/回答了这个问题（这也是research的一般过程）。

## LLM Safety

1. [Jailbroken: How Does LLM Safety Training Fail?](http://arxiv.org/abs/2307.02483)

2. [GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher](http://arxiv.org/abs/2308.06463)

3. [PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety](http://arxiv.org/abs/2401.11880)

## Agent Safety

1. [The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models](https://www.semanticscholar.org/paper/9966978b065c7bff55bf090a61038b9578197907)

2. [Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents](https://arxiv.org/abs/2402.11208)

3. [AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents](http://arxiv.org/abs/2410.09024)

你需要提交给我一个md文件，来记录你对这些论文的思考。

**最终提交的结果中不允许包含直接由 AI 生成的内容。请在充分理解相关知识后自行作答。**
